---
title: "Llm Sample Parameters"
date: 2025-07-09T18:10:38+08:00
# bookComments: false
# bookSearchExclude: false
---

# LLM生成参数

## temperature

在没有temperature的情况下，模型使用标准softmax函数将logits转换为概率:
$$
P(xi) = exp(z_i) / Σ exp(z_j)
$$
temperature被引入到softmax函数中:
$$
P(xi) = exp(z_i/T) / Σ exp(z_j/T)
$$
temperature参数用于改变概率分布的形状，低温度（<1）让概率分布变得更尖锐，当T→0时，概率分布趋向于one-hot，高温度（>1）让概率分布变得更平坦，当T→∞时，所有token的概率趋向于相等（均匀分布）

### 示例

假设我们有3个候选token，它们的logits分别是：

```python
Token A: logit = 3.0

Token B: logit = 2.0

Token C: logit = 1.0
```

当 temperature = 1.0 时：

```python
P(A) = exp(3.0) / [exp(3.0) + exp(2.0) + exp(1.0)] ≈ 0.665
P(B) = exp(2.0) / [exp(3.0) + exp(2.0) + exp(1.0)] ≈ 0.245
P(C) = exp(1.0) / [exp(3.0) + exp(2.0) + exp(1.0)] ≈ 0.090
```

当 temperature = 0.5 时（低温度）：

```python
P(A) = exp(3.0/0.5) / [exp(3.0/0.5) + exp(2.0/0.5) + exp(1.0/0.5)] ≈ 0.878
P(B) = exp(2.0/0.5) / [exp(3.0/0.5) + exp(2.0/0.5) + exp(1.0/0.5)] ≈ 0.119
P(C) = exp(1.0/0.5) / [exp(3.0/0.5) + exp(2.0/0.5) + exp(1.0/0.5)] ≈ 0.003
```

当 temperature = 2.0 时（高温度）：

```python
P(A) = exp(3.0/2.0) / [exp(3.0/2.0) + exp(2.0/2.0) + exp(1.0/2.0)] ≈ 0.506
P(B) = exp(2.0/2.0) / [exp(3.0/2.0) + exp(2.0/2.0) + exp(1.0/2.0)] ≈ 0.307
P(C) = exp(1.0/2.0) / [exp(3.0/2.0) + exp(2.0/2.0) + exp(1.0/2.0)] ≈ 0.187
```



## top_p

top_p是一种动态截断采样方法，它会：

- 将所有token按概率从高到低排序

- 计算累积概率，直到达到或超过p值

- 只从这个"核心集合"中采样，忽略其余token

### 示例

假设模型对下一个token的原始概率分布如下：

```python
Token:      概率:
"和"        0.08
"的"        0.30
"了"        0.25
"是"        0.15
"在"        0.10
"与"        0.05
"及"        0.04
"或"        0.03
```

按概率排序后：

```python
Token:      概率:
"的"        0.30
"了"        0.25
"是"        0.15
"在"        0.10
"和"        0.08
"与"        0.05
"及"        0.04
"或"        0.03
```

当 top_p = 0.5 时：

```python
累积过程：
"的" = 0.30 (累积: 0.30)
"了" = 0.25 (累积: 0.55) ← 超过0.5，停止

结果：只考虑"的"和"了"
重新归一化：
"的" = 0.30 / 0.55 ≈ 0.545
"了" = 0.25 / 0.55 ≈ 0.455
其他 = 0
```

当 top_p = 0.9 时：

```python
累积过程：
"的" = 0.30 (累积: 0.30)
"了" = 0.25 (累积: 0.55)
"是" = 0.15 (累积: 0.70)
"在" = 0.10 (累积: 0.80)
"和" = 0.08 (累积: 0.88)
"与" = 0.05 (累积: 0.93) ← 超过0.9，停止

结果：考虑前6个token，忽略"及"和"或"
```



## top_k

* top_k是一种采样策略，它只考虑概率最高的k个token，将其余token的概率设为0，然后在这k个token中进行采样。

* k=1时变为贪婪解码

* top_p和top_k都是采样策略，一般情况下top_p比top_k更常用，因为更灵活

### 示例

```python
# 原始概率分布
tokens = ['好', '很', '非常', '特别', '真', '太', '挺', '极']
probs = [0.30, 0.25, 0.15, 0.10, 0.08, 0.06, 0.04, 0.02]

# top_k = 3 时
保留: ['好'(0.30), '很'(0.25), '非常'(0.15)]
过滤: ['特别', '真', '太', '挺', '极']

# 重新归一化
新概率分布:
'好': 0.30/(0.30+0.25+0.15) = 0.43
'很': 0.25/(0.30+0.25+0.15) = 0.36
'非常': 0.15/(0.30+0.25+0.15) = 0.21
其他: 0
```



## Beam Search

* Beam Search在每一步保留最可能的k个候选序列（k称为beam size），而不是只保留一个最佳序列（贪婪解码）,并在序列级别选择最优路径

* top_k=1和beam size=1的输出一般相同

### 示例

```python
候选:
"我最" (0.5)
"我很" (0.3)
"我非常" (0.2)
# 保留所有3个（beam_size=3）

# 从"我最"扩展:
"我最喜欢" (0.5 × 0.2 = 0.10)
"我最爱" (0.5 × 0.1 = 0.05)

# 从"我很"扩展:
"我很喜欢" (0.3 × 0.8 = 0.24)
"我很爱" (0.3 × 0.7 = 0.21)

# 从"我非常"扩展:
"我非常喜欢" (0.2 × 0.9 = 0.18)
"我非常爱" (0.2 × 0.8 = 0.16)

# 现在有6个候选，需要保留top-3
所有候选排序:
1. "我很喜欢" (0.24)    ← 保留
2. "我很爱" (0.21)      ← 保留
3. "我非常喜欢" (0.18)  ← 保留
4. "我非常爱" (0.16)    ✗ 被淘汰
5. "我最喜欢" (0.10)    ✗ 被淘汰
6. "我最爱" (0.05)      ✗ 被淘汰


Step 1:           Step 2:                    Step 3:
                  我最─┬─喜欢(0.10)✗          保留:
我───┬─最(0.5)────────┴─爱(0.05)✗            1.我很喜欢(0.24)
     │                                      2.我很爱(0.21)
     ├─很(0.3)────我很─┬─喜欢(0.24)✓        	3.我非常喜欢(0.18)
     │                 └─爱(0.21)✓
     │                                       淘汰:
     └─非常(0.2)──我非常┬─喜欢(0.18)✓       	4.我非常爱(0.16)
                       └─爱(0.16)✗          5.我最喜欢(0.10)
                                            6.我最爱(0.05)
```

### 与采样方法对比

| 特性     | Beam Search                | Top-k/Top-p采样 |
| :------- | :------------------------- | :-------------- |
| 确定性   | 是（相同输入得到相同输出） | 否（随机性）    |
| 多样性   | 低                         | 高              |
| 适用场景 | 翻译、摘要                 | 对话、创作      |

```python
# Beam Search
输入 → 计算得分 → 排序 → 选择最高分 → 输出
         ↑              ↑           ↑
      确定性操作    确定性操作   确定性操作
```

```python
# 采样方法
输入 → 计算概率 → 筛选候选 → 随机采样 → 输出
         ↑            ↑          ↑
      确定性操作   确定性操作   随机操作！
```

### 使用配合

* temperature一般与top_p/top_k等采样方法配合使用

* temperature可以beam search配合改变最佳路径的选择，增加输出的多样性，但一般不会这样使用。因为beam search的设计初衷是找到概率最高的完整序列，它相信模型的判断，想要找到模型认为最好的答案，temperature会扭曲模型的原始概率分布，这与beam search的目标相悖。beam search的主要优势是可靠性和质量保证，加入temperature后：

  - 不再保证找到真正的最优序列

  - 结果质量变得不稳定

  - 失去了在生产环境中的可预测性

  ```python
  # 原始情况（无temperature）
  "我喜欢" → 
    - "吃"(0.6) → "苹果"(0.8) = 0.48 ✓ 最优路径
    - "看"(0.3) → "电影"(0.7) = 0.21
    
  # 加入temperature=0.5（低温，分布更尖锐）
  "我喜欢" → 
    - "吃"(0.9) → "苹果"(0.95) = 0.855 ✓ 更加确定是最优
    - "看"(0.08) → "电影"(0.04) = 0.0032
  
  # 加入temperature=2.0（高温，分布更平缓）
  "我喜欢" → 
    - "吃"(0.4) → "苹果"(0.5) = 0.20
    - "看"(0.35) → "电影"(0.6) = 0.21 ✓ 可能变成最优！改变了beam search的最优选择
  ```

* beam search和top_p/top_k等采样方法不在一起使用，因为beam Search是在序列级别选择最优路径，而top_k/top_p是在token级别进行采样，组合会造成逻辑混乱。例如：

  ```python
  Beam Search想要："今天天气很好"（最优路径）
  Top-k采样可能选："今天天气真糟"（随机选择）
  
  两者的目标相互矛盾
  ```

  
